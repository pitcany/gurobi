{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718ac693",
   "metadata": {},
   "source": [
    "\n",
    "## Using XGBoost: Predict **Time** from **Total Clay** and **Total Lead**\n",
    "\n",
    "A new criteria to consider is given to us -- time. The bulk of the chips are made out of clay and lead, with the expensive chips containing silver and gold. Let's suppose the time it takes to make a batch of chips isn't necessarily dependent on the number of chips, but by the amount of clay and lead in the batch (we can ignore the silver and gold). \n",
    "\n",
    "Based on knowledge of the process, we don't have an exact form for this relationship, but we have simulated data on the time it takes to make a batch of chips based in the total clay and lead amounts. \n",
    "\n",
    "> **Data requirement:** a CSV with columns: `total_clay`, `total_lead`, `time`.\n",
    "\n",
    "We can train a machine learning model to represent the relationship and use the `gurobi-machine-learning` package to implement it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09620495",
   "metadata": {},
   "source": [
    "### ML Model\n",
    "\n",
    "First, use the data we have to train a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "### Install the Gurobi machine learning package and load the required function\n",
    "%pip install gurobi-machinelearning\n",
    "from gurobi_ml import add_predictor_constr\n",
    "\n",
    "df = pd.read_csv('data_files/synthetic_time.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea04a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"total_clay\",\"total_lead\"]].copy()\n",
    "y = df[\"time\"].astype(float).values\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "ml_model = XGBRegressor(n_estimators=120, learning_rate=0.02, max_depth=2, random_state=42)\n",
    "\n",
    "scores = cross_val_score(ml_model, X, y, cv=cv, scoring=\"neg_root_mean_squared_error\")\n",
    "print(\"CV RMSE (mean±std):\", -scores.mean(), \"±\", scores.std())\n",
    "\n",
    "# Refit on all data for your final model:\n",
    "ml_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build grid\n",
    "n_grid = 60\n",
    "clay_vals = np.linspace(df[\"total_clay\"].min(), df[\"total_clay\"].max(), n_grid)\n",
    "lead_vals = np.linspace(df[\"total_lead\"].min(), df[\"total_lead\"].max(), n_grid)\n",
    "CLAY, LEAD = np.meshgrid(clay_vals, lead_vals)\n",
    "\n",
    "grid_df = pd.DataFrame({\n",
    "    \"total_clay\": CLAY.ravel(),\n",
    "    \"total_lead\": LEAD.ravel(),\n",
    "})\n",
    "Z = ml_model.predict(grid_df).reshape(CLAY.shape)\n",
    "\n",
    "# 3D surface\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(CLAY, LEAD, Z, linewidth=0, antialiased=True, alpha=0.9)\n",
    "ax.set_xlabel(\"Total Clay\")\n",
    "ax.set_ylabel(\"Total Lead\")\n",
    "ax.set_zlabel(\"Predicted Time\")\n",
    "ax.set_title(\"XGBoost Prediction Surface\")\n",
    "ax.view_init(elev=22, azim=35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5b147",
   "metadata": {},
   "source": [
    "### Back to the Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657fe8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Re-import other data\n",
    "on_hand = pd.read_csv('data_files/ing_amounts.csv', index_col=['ingredient']).squeeze()\n",
    "chips_data = pd.read_csv('data_files/chips_data.csv', index_col=['chips']).squeeze()\n",
    "recipes = pd.read_csv('data_files/recipes.csv', index_col=['chips', 'ingredients']).squeeze()\n",
    "\n",
    "ingredients = on_hand.index.to_list()\n",
    "chips = chips_data.index.to_list()\n",
    "\n",
    "### Create a new model\n",
    "mo_model = gp.Model(\"Poker Chips\")\n",
    "\n",
    "### Decision variables\n",
    "x = mo_model.addVars(chips, vtype=GRB.INTEGER, name=\"chips\")\n",
    "\n",
    "### Ingredient constraint\n",
    "ingredient_usage = mo_model.addConstrs((gp.quicksum(x[c] * recipes[c, i] for c in chips) <= on_hand[i] for i in ingredients), name=\"ingredient_usage\")\n",
    "\n",
    "### Objective function\n",
    "total_chips = x.sum()\n",
    "mo_model.setObjective(total_chips, sense=GRB.MAXIMIZE)\n",
    "mo_model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results0 = [{\"chip\": c, \"count0\": abs(x[c].X)} for c in chips]\n",
    "results0_df = pd.DataFrame(results0)\n",
    "results0_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d092e3",
   "metadata": {},
   "source": [
    "#### Using Gurobi Machine Learning\n",
    "\n",
    "The time to use this package is when there is an intersection between some of the **features in the machine learning model** and some of the **decision variables in the optimization model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dda880",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add decision variables for the inputs and outputs of the ML model\n",
    "total_clay = mo_model.addVar(name = \"total_clay\")\n",
    "total_lead = mo_model.addVar(name = \"total_lead\")\n",
    "total_time = mo_model.addVar(name = \"total_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c076ec",
   "metadata": {},
   "source": [
    "Since we only need the totals for clay and lead used, we need to set new constraints to make this relationship hold between our decision variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_model.addConstr(total_clay == gp.quicksum(recipes[c,'clay'] * x[c] for c in chips))\n",
    "mo_model.addConstr(total_lead == gp.quicksum(recipes[c,'lead'] * x[c] for c in chips))\n",
    "mo_model.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d50e7",
   "metadata": {},
   "source": [
    "Create a pandas data frame that includes the actual decision variables. Make sure to keep the column headers the same between this data frame and the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdaf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_feats = pd.DataFrame({\"total_clay\":[total_clay],\"total_lead\":[total_lead]})\n",
    "m_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2dd8ea",
   "metadata": {},
   "source": [
    "To add the predictor constraint, all we need is one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36957a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr = add_predictor_constr(mo_model, ml_model, m_feats, total_time)\n",
    "pred_constr.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a7e69f",
   "metadata": {},
   "source": [
    "In the original problem, the value of the chips made was 99,205. Suppose we want to create approximately the same value (say 90,000) but at minimal expected time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the objective to minimize the output decision variable of our regression\n",
    "mo_model.setObjective(total_time, sense=GRB.MINIMIZE)\n",
    "\n",
    "### Add a constraint for the min number of chips to make\n",
    "count_const = mo_model.addConstr(total_chips >= 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f0545",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use this if you want to easily update the above constraint\n",
    "count_const.RHS = ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d41f96",
   "metadata": {},
   "source": [
    "Optimize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_model.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304fd7b1",
   "metadata": {},
   "source": [
    "Let's store the new results and merge with the first solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d43040",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = [{\"chip\": c, \"count1\": abs(x[c].X)} for c in chips]\n",
    "results1_df = pd.DataFrame(results1)\n",
    "results = results1_df.merge(results0_df, on=\"chip\", how=\"left\")\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
